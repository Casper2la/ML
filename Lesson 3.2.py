import pandas as pd
import numpy as np

# All print() is commented out

# В нашем Big Data датасэте появились новые наблюдения! Давайте немного посчитаем энтропию,
# чтобы лучше понять, формализуемость разделения на группы.
# Формат записи - энтропия в группе, где переменная равна 0 и энтропия в группе,
# где переменная равна 1 (десятичный разделитель - точка, округляйте до 2-ого знака при необходимости).

# Энтропия при разделении по фиче Шерстист в группах, где Шерстист равно 0 и 1 соответственно, составляет
# Энтропия при разделении по фиче Гавкает в группах, где Гавкает равно 0 и 1 соответственно, составляет
# Энтропия при разделении по фиче Лазает по деревьям в группах, где эта фича равна 0 и 1 соответственно, составляет

catdog = pd.read_csv('Lesson 3.2 data/cats.csv', index_col=0)
print(catdog)

def entropy(data, base=None):
  vc = pd.Series(data).value_counts(normalize=True, sort=False)
  base = e if base is None else base
  return -(vc * np.log(vc)/np.log(base)).sum()

print(entropy(pd.Series(catdog['Шерстит'])))